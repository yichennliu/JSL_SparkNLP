{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark and Spark NLP\n",
        "!pip install -q pyspark==3.3.0  spark-nlp==4.3.2"
      ],
      "metadata": {
        "id": "gx_yH4F-gmqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Wj87gRgi7J",
        "outputId": "3a6f0dc6-89ee-430d-c4e1-b04f9e67bc27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "+-----------------------------------------------------------------------+\n",
            "|document                                                               |\n",
            "+-----------------------------------------------------------------------+\n",
            "|[{document, 0, 28, I love working with SparkNLP., {sentence -> 0}, []}]|\n",
            "|[{document, 0, 14, Today is sunny., {sentence -> 0}, []}]              |\n",
            "+-----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "# Let Spark NLP start the SparkSession\n",
        "spark = sparknlp.start()\n",
        "\n",
        "data = [\n",
        "    (1, \"I love working with SparkNLP.\"),\n",
        "    (2, \"Today is sunny.\")\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "columns = [\"id\", \"text\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"processed_text\")"
      ],
      "metadata": {
        "id": "yvlgSdPIgnSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result = document_assembler.transform(df)\n",
        "\n",
        "result.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4TLsgDOh0n9",
        "outputId": "54c2c0b6-b129-4700-b309-b2d41deed58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-----------------------------+-----------------------------------------------------------------------+\n",
            "|id |text                         |processed_text                                                         |\n",
            "+---+-----------------------------+-----------------------------------------------------------------------+\n",
            "|1  |I love working with SparkNLP.|[{document, 0, 28, I love working with SparkNLP., {sentence -> 0}, []}]|\n",
            "|2  |Today is sunny.              |[{document, 0, 14, Today is sunny., {sentence -> 0}, []}]              |\n",
            "+---+-----------------------------+-----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import Tokenizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "tokenizer = Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "\n",
        "pipeline = Pipeline(stages=[document_assembler, tokenizer])\n",
        "model = pipeline.fit(df)\n",
        "result = model.transform(df)\n",
        "\n",
        "result.select(\"token.result\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-79nVFoiIua",
        "outputId": "c362ef21-985b-43f1-e7de-8acdf3c4d264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------+\n",
            "|result                               |\n",
            "+-------------------------------------+\n",
            "|[I, love, working, with, SparkNLP, .]|\n",
            "|[Today, is, sunny, .]                |\n",
            "+-------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition with BERT\n"
      ],
      "metadata": {
        "id": "5Td81IYT1KZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "example_df = spark.createDataFrame([[\"Microsoft founder Bill Gates plans to build a new factory in Germany.\"]]).toDF(\"text\")\n",
        "\n",
        "example_df = pipeline.fit(example_df).transform(example_df)"
      ],
      "metadata": {
        "id": "J4afzMLW3FnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import Tokenizer, BertForTokenClassification\n",
        "import pyspark.sql.functions as F\n",
        "bert_tagger = BertForTokenClassification.pretrained(\"bert_base_token_classifier_conll03\", \"en\") \\\n",
        "        .setInputCols(['document', 'token']) \\\n",
        "        .setOutputCol('ner')\\\n",
        "        .setMaxSentenceLength(512)\\\n",
        "        .setCaseSensitive(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U32WjWN0j_G",
        "outputId": "6091074b-903f-43df-d4a2-1d511a042072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_base_token_classifier_conll03 download started this may take some time.\n",
            "Approximate size to download 385.4 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = bert_tagger.transform(example_df)\n",
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmpNQvC93O2P",
        "outputId": "787c3c14-9db9-43d7-b609-2a79c0acbd24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|                 ner|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Microsoft founder...|[{document, 0, 68...|[{token, 0, 8, Mi...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.posexplode(\"token.result\").alias(\"pos\", \"token\"), \"ner\") \\\n",
        "    .select(F.col(\"token\"), F.col(\"ner\").getItem(F.col(\"pos\")).alias(\"ner_label\")) \\\n",
        "    .show(50, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFdkdbC33TUS",
        "outputId": "825b6359-1024-45fb-9004-e9571ccbdc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|token    |ner_label                                                                                                                                                                                                                                                                    |\n",
            "+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Microsoft|{named_entity, 0, 8, B-ORG, {B-LOC -> 6.298694E-4, I-ORG -> 2.1694727E-4, I-MISC -> 1.0996349E-4, I-LOC -> 1.5734222E-5, I-PER -> 6.565089E-5, B-MISC -> 0.0021291883, B-ORG -> 0.99516934, word -> Microsoft, O -> 5.5495714E-4, sentence -> 0, B-PER -> 0.0011083572}, []} |\n",
            "|founder  |{named_entity, 10, 16, O, {B-LOC -> 1.4008918E-5, I-ORG -> 4.6620044E-5, I-MISC -> 1.533285E-5, I-LOC -> 1.2327288E-5, I-PER -> 9.304739E-6, B-MISC -> 3.2397707E-5, B-ORG -> 2.5129493E-5, word -> founder, O -> 0.9998164, sentence -> 0, B-PER -> 2.8461598E-5}, []}      |\n",
            "|Bill     |{named_entity, 18, 21, B-PER, {B-LOC -> 4.1961565E-4, I-ORG -> 7.457276E-5, I-MISC -> 5.0252656E-5, I-LOC -> 2.5222469E-5, I-PER -> 1.6254443E-4, B-MISC -> 5.0020654E-4, B-ORG -> 0.0020405783, word -> Bill, O -> 3.2645394E-4, sentence -> 0, B-PER -> 0.99640054}, []}   |\n",
            "|Gates    |{named_entity, 23, 27, I-PER, {B-LOC -> 1.6354877E-4, I-ORG -> 9.967994E-4, I-MISC -> 3.116197E-4, I-LOC -> 1.373681E-4, I-PER -> 0.9972887, B-MISC -> 1.3754466E-4, B-ORG -> 1.1814749E-4, word -> Gates, O -> 1.280688E-4, sentence -> 0, B-PER -> 7.1822124E-4}, []}      |\n",
            "|plans    |{named_entity, 29, 33, O, {B-LOC -> 9.291043E-6, I-ORG -> 1.6700438E-5, I-MISC -> 8.197862E-6, I-LOC -> 6.5651966E-6, I-PER -> 5.967727E-6, B-MISC -> 1.324781E-5, B-ORG -> 1.5393816E-5, word -> plans, O -> 0.9999107, sentence -> 0, B-PER -> 1.3895303E-5}, []}          |\n",
            "|to       |{named_entity, 35, 36, O, {B-LOC -> 8.359211E-6, I-ORG -> 1.4973059E-5, I-MISC -> 7.0551005E-6, I-LOC -> 8.33244E-6, I-PER -> 4.922494E-6, B-MISC -> 1.1780193E-5, B-ORG -> 1.4124837E-5, word -> to, O -> 0.99992114, sentence -> 0, B-PER -> 9.33023E-6}, []}              |\n",
            "|build    |{named_entity, 38, 42, O, {B-LOC -> 9.359221E-6, I-ORG -> 1.5982107E-5, I-MISC -> 8.207583E-6, I-LOC -> 7.5804865E-6, I-PER -> 4.9172822E-6, B-MISC -> 1.775511E-5, B-ORG -> 1.7233242E-5, word -> build, O -> 0.9999064, sentence -> 0, B-PER -> 1.25480055E-5}, []}        |\n",
            "|a        |{named_entity, 44, 44, O, {B-LOC -> 8.915688E-6, I-ORG -> 1.8389259E-5, I-MISC -> 7.4566497E-6, I-LOC -> 8.629385E-6, I-PER -> 4.6963382E-6, B-MISC -> 1.4352125E-5, B-ORG -> 1.662E-5, word -> a, O -> 0.9999107, sentence -> 0, B-PER -> 1.0244308E-5}, []}                |\n",
            "|new      |{named_entity, 46, 48, O, {B-LOC -> 9.855103E-6, I-ORG -> 1.7640676E-5, I-MISC -> 8.095036E-6, I-LOC -> 9.687445E-6, I-PER -> 5.1227034E-6, B-MISC -> 2.2495122E-5, B-ORG -> 1.9930312E-5, word -> new, O -> 0.9998942, sentence -> 0, B-PER -> 1.2988541E-5}, []}           |\n",
            "|factory  |{named_entity, 50, 56, O, {B-LOC -> 1.846462E-5, I-ORG -> 4.85002E-5, I-MISC -> 1.6418224E-5, I-LOC -> 1.6704682E-5, I-PER -> 1.01747055E-5, B-MISC -> 5.7257697E-5, B-ORG -> 3.8976177E-5, word -> factory, O -> 0.9997708, sentence -> 0, B-PER -> 2.2694703E-5}, []}      |\n",
            "|in       |{named_entity, 58, 59, O, {B-LOC -> 1.2143756E-5, I-ORG -> 2.1639366E-5, I-MISC -> 9.320799E-6, I-LOC -> 1.6001286E-5, I-PER -> 6.0207176E-6, B-MISC -> 1.7721723E-5, B-ORG -> 1.2977035E-5, word -> in, O -> 0.99989307, sentence -> 0, B-PER -> 1.1129831E-5}, []}         |\n",
            "|Germany  |{named_entity, 61, 67, B-LOC, {B-LOC -> 0.999125, I-ORG -> 4.4947432E-5, I-MISC -> 2.5468542E-5, I-LOC -> 1.6053181E-4, I-PER -> 5.4022752E-5, B-MISC -> 2.2425575E-4, B-ORG -> 1.11335125E-4, word -> Germany, O -> 1.4846126E-4, sentence -> 0, B-PER -> 1.0596997E-4}, []}|\n",
            "|.        |{named_entity, 68, 68, O, {B-LOC -> 1.0643327E-5, I-ORG -> 2.0530095E-5, I-MISC -> 1.1513528E-5, I-LOC -> 1.4699969E-5, I-PER -> 6.8845716E-6, B-MISC -> 1.630624E-5, B-ORG -> 1.6786284E-5, word -> ., O -> 0.9998911, sentence -> 0, B-PER -> 1.1521217E-5}, []}           |\n",
            "+---------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.printSchema()  # Check the schema of the DataFrame\n",
        "result.select(\"ner.result\").show(truncate=False)  # Inspect the 'ner.result' column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeK1iAWc1vuR",
        "outputId": "2a634e7c-9881-41dc-cd76-70f78de6062d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n",
            "+-------------------------------------------------------+\n",
            "|result                                                 |\n",
            "+-------------------------------------------------------+\n",
            "|[B-ORG, O, B-PER, I-PER, O, O, O, O, O, O, O, B-LOC, O]|\n",
            "+-------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tagger.extractParamMap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vak2AcUB4i5X",
        "outputId": "771b5c75-04d9-4304-c0db-744de14dc9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='batchSize', doc='Size of every batch'): 8,\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='engine', doc='Deep Learning engine used for this model'): 'tensorflow',\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='maxSentenceLength', doc='Max sentence length to process'): 512,\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='caseSensitive', doc='whether to ignore case in tokens for embeddings matching'): True,\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='inputCols', doc='previous annotations columns, if renamed'): ['document',\n",
              "  'token'],\n",
              " Param(parent='BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89', name='outputCol', doc='output annotation column. can be left default.'): 'ner'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# Load pre-trained NER pipeline\n",
        "pipeline = PretrainedPipeline(\"recognize_entities_dl\", lang=\"en\")\n",
        "\n",
        "# Sample text\n",
        "text = \"IBM, which has an office in Germany, is a leader in AI and NLP.\"\n",
        "\n",
        "# Annotate the text\n",
        "result = pipeline.annotate(text)\n",
        "\n",
        "# Print the results\n",
        "print(result['entities'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_u0le5Zw4k0R",
        "outputId": "5d0d2708-3140-44bd-e943-d874a65e4481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 160.1 MB\n",
            "[OK!]\n",
            "['IBM', 'Germany', 'AI', 'NLP']\n"
          ]
        }
      ]
    }
  ]
}